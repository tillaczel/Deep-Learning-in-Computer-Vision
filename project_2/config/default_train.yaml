#defaults:
hydra:
  run:
    dir: ./

model:
  pretrained: true
  out_dim: 1
  in_dim: 1

training:
  max_epochs: 50
  batch_size: 64
  optimizer:
    name: adam
    lr: 0.0003
  early_stopping:
    monitor: 'val_loss'
    stopping_patience: 5
  scheduler:
    monitor: val_loss
    mode: min
    name: plateau
    patience: 3
    min_lr: 0.00001
    factor: 0.5
  model_checkpoint:
    monitor: 'val_loss'
data:
  size: 128
  url: 'https://courses.compute.dtu.dk/02514/project_data/LIDC_DLCV_version.zip'
  path: './data/'
  seg_reduce: 0
  train_augmentation:
    - 'random_crop'
    - 'color_jitter'
overlap: 0.2